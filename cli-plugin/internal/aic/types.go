// /*
// Copyright 2025 The Grove Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// */

// Package aic provides AIConfigurator integration for kubectl-grove.
package aic

// Backend constants
const (
	BackendSGLang = "sglang"
	BackendVLLM   = "vllm"
	BackendTRTLLM = "trtllm"
)

// Database mode constants
const (
	DatabaseModeSilicon   = "SILICON"
	DatabaseModeHybrid    = "HYBRID"
	DatabaseModeEmpirical = "EMPIRICAL"
	DatabaseModeSOL       = "SOL"
)

// Deployment mode constants
const (
	DeploymentModeDisagg = "disagg"
	DeploymentModeAgg    = "agg"
)

// TaskConfig holds the configuration for AIConfigurator execution.
type TaskConfig struct {
	// Model is the model name (e.g., QWEN3_32B)
	ModelName string

	// HuggingFaceID is the optional HuggingFace model ID
	HuggingFaceID string

	// System is the hardware system type (e.g., h200_sxm)
	SystemName string

	// DecodeSystemName is the optional system for decode workers (disagg mode)
	DecodeSystemName string

	// TotalGPUs is the total number of GPUs available
	TotalGPUs int

	// Backend is the inference backend (e.g., sglang, vllm, trtllm)
	BackendName string

	// BackendVersion is the optional backend version
	BackendVersion string

	// ISL is the input sequence length
	ISL int

	// OSL is the output sequence length
	OSL int

	// Prefix is the prefix cache length
	Prefix int

	// TTFT is the target time-to-first-token in milliseconds
	TTFT float64

	// TPOT is the target time-per-output-token in milliseconds
	TPOT float64

	// RequestLatency is the optional end-to-end request latency target
	RequestLatency float64

	// DatabaseMode is the database mode (SILICON, HYBRID, EMPIRICAL, SOL)
	DatabaseMode string

	// SaveDir is the directory to save generated configs
	SaveDir string

	// Debug enables debug mode
	Debug bool
}

// GeneratorConfig represents the configuration generated by aiconfigurator.
// This matches the generator_config.yaml output structure.
// Note: sigs.k8s.io/yaml uses JSON tags, not YAML tags.
type GeneratorConfig struct {
	K8s     K8sConfig     `json:"k8s"`
	Workers WorkersConfig `json:"workers"`
	Params  ParamsConfig  `json:"params"`
}

// K8sConfig holds Kubernetes-related configuration from aiconfigurator.
type K8sConfig struct {
	NamePrefix         string `json:"name_prefix"`
	K8sNamespace       string `json:"k8s_namespace"`
	K8sImage           string `json:"k8s_image"`
	K8sImagePullSecret string `json:"k8s_image_pull_secret"`
	K8sEngineMode      string `json:"k8s_engine_mode"`
	K8sModelCache      string `json:"k8s_model_cache"`
	Mode               string `json:"mode"` // "disagg" or "agg"
	RouterMode         string `json:"router_mode"`
	IsKV               bool   `json:"is_kv"`
	EnableRouter       bool   `json:"enable_router"`
	Name               string `json:"name"`
	UseEngineCM        bool   `json:"use_engine_cm"`
	PrefillEngineArgs  string `json:"prefill_engine_args"`
	DecodeEngineArgs   string `json:"decode_engine_args"`
	AggEngineArgs      string `json:"agg_engine_args"`
}

// WorkersConfig holds the number of workers and GPUs for each role.
type WorkersConfig struct {
	PrefillWorkers       int `json:"prefill_workers"`
	DecodeWorkers        int `json:"decode_workers"`
	AggWorkers           int `json:"agg_workers"`
	PrefillGPUsPerWorker int `json:"prefill_gpus_per_worker"`
	DecodeGPUsPerWorker  int `json:"decode_gpus_per_worker"`
	AggGPUsPerWorker     int `json:"agg_gpus_per_worker"`
}

// ParamsConfig holds the parallelization parameters for different worker types.
type ParamsConfig struct {
	Prefill map[string]interface{} `json:"prefill"`
	Decode  map[string]interface{} `json:"decode"`
	Agg     map[string]interface{} `json:"agg"`
}

// WorkerParams represents the parallelization parameters for a single worker type.
type WorkerParams struct {
	TensorParallelSize    int `json:"tensor_parallel_size"`
	PipelineParallelSize  int `json:"pipeline_parallel_size"`
	DataParallelSize      int `json:"data_parallel_size"`
	MoETensorParallelSize int `json:"moe_tensor_parallel_size"`
	MoEExpertParallelSize int `json:"moe_expert_parallel_size"`
}

// DeploymentPlan represents a complete deployment plan for rendering.
type DeploymentPlan struct {
	Mode          string // "disagg" or "agg"
	Config        *GeneratorConfig
	OutputPath    string
	ModelName     string
	BackendName   string
	HuggingFaceID string
	Namespace     string
	Image         string
}

// GeneratedFile represents a generated manifest file.
type GeneratedFile struct {
	// Path is the absolute path to the generated file
	Path string

	// Plan is the deployment plan that was used to generate this file
	Plan *DeploymentPlan
}

// GetWorkerParams extracts WorkerParams from a params map.
func GetWorkerParams(params map[string]interface{}) WorkerParams {
	return WorkerParams{
		TensorParallelSize:    getIntFromMap(params, "tensor_parallel_size"),
		PipelineParallelSize:  getIntFromMap(params, "pipeline_parallel_size"),
		DataParallelSize:      getIntFromMap(params, "data_parallel_size"),
		MoETensorParallelSize: getIntFromMap(params, "moe_tensor_parallel_size"),
		MoEExpertParallelSize: getIntFromMap(params, "moe_expert_parallel_size"),
	}
}

// getIntFromMap safely retrieves an int value from a map.
func getIntFromMap(m map[string]interface{}, key string) int {
	if m == nil {
		return 0
	}
	if v, ok := m[key]; ok {
		switch val := v.(type) {
		case int:
			return val
		case float64:
			return int(val)
		case int64:
			return int(val)
		}
	}
	return 0
}
