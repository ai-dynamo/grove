# kubectl-grove: Requirements & Design Document

**Status:** Draft
**Authors:** Grove PM Team
**Last Updated:** January 2026
**Branch:** `arborist-v2`
**Binary:** `kubectl-grove` (kubectl plugin)

---

## Executive Summary

`kubectl grove` is Grove's CLI plugin for managing, visualizing, and diagnosing AI inference workloads on Kubernetes. This document outlines the roadmap to transform the existing diagnostics tool into a comprehensive operations tool that **differentiates Grove from RBG** through superior observability and closed-loop feedback with AIConfigurator.

### The Pitch

> **RBG helps you deploy. kubectl grove helps you succeed.**
>
> RBG can generate a config from AIConfigurator and deploy it. But then what?
>
> kubectl grove shows you:
> - **Where** your pods actually landed (topology view)
> - **How well** they landed (PlacementScore)
> - **Whether** they're meeting your plan (plan vs actual)
> - **Why** they might be underperforming (diagnosis)
> - **What** to do about it (recommendations)

---

## Key Decisions

| Decision | Choice | Rationale |
|----------|--------|-----------|
| CLI Naming | `kubectl grove` | Matches RBG's `kubectl rbg` pattern, discoverable via krew |
| P0 Priority | Parallel (status + topology) | Build parity AND differentiation together |
| Plan Storage | ConfigMap with `grove.io/aic-plan` label | Simple, no CRD needed |
| TUI Priority | Phase 3 (after core CLI, before metrics) | High value, user loves TUI |
| Code Location | `operator/cmd/kubectl-grove/` | Keep with operator code, delete empty `cli-plugin/` |
| Metrics Source | Direct pod scraping | Works without Prometheus operator dependency |

---

## Background & Motivation

### Competitive Context

RBG (RoleBasedGroup) has shipped several features that Grove lacks:

| Feature | RBG Status | Grove Status |
|---------|------------|--------------|
| `kubectl rbg status` | âœ… Progress bars, role status | âŒ Empty placeholder |
| `kubectl rbg llm generate` | âœ… AIConfigurator integration | âŒ Not implemented |
| `kubectl rbg rollout history/undo` | âœ… Revision tracking | âŒ No revision system |
| In-place updates | âœ… InstanceSet | âŒ Not implemented |
| Rolling update coordination | âœ… maxSkew across roles | âŒ Basic hash-triggered |

### Grove's Unique Advantages

Grove has data that RBG doesn't expose:

1. **PlacementScore** (0.0-1.0) - Network optimality score per PodGang
2. **ClusterTopology** CRD - Platform-agnostic topology hierarchy
3. **TopologyConstraint.PackDomain** - rack, host, numa, etc.
4. **ReuseReservationRef** - Placement reuse hints during updates
5. **TerminationDelay** countdown - Time until gang termination
6. **ScheduleGatedReplicas** - Two-tier gang scheduling visibility

**Strategy:** Don't just catch up to RBGâ€”leapfrog them by building the observability layer they're missing.

---

## Current State (Diagnostics MVP)

The current implementation (from `gflarity/diagnostics_cli_command` branch) provides:

```bash
kubectl grove diag -n <namespace> -o <output-dir>
```

**Collectors:**
1. `CollectOperatorLogs` - Last 2000 lines from grove-operator pods
2. `CollectGroveResources` - YAML dump of PodCliqueSets, PodCliques, PodCliqueScalingGroups, PodGangs
3. `CollectPodDetails` - Pod table with phase, ready status, node, conditions
4. `CollectEvents` - Last 10 minutes of Kubernetes events

**Output:** Files written to `grove-diagnostics-{timestamp}/` directory.

**Limitations:**
- One-shot dump only, no interactive mode
- No visualization
- No AIConfigurator integration
- No topology awareness
- No metrics integration

---

## Target Architecture

```
operator/cmd/kubectl-grove/
â”œâ”€â”€ main.go                     # CLI entry point
â”œâ”€â”€ cli.go                      # Kong CLI definitions
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ commands/               # Subcommand implementations
â”‚   â”‚   â”œâ”€â”€ status.go           # kubectl grove status
â”‚   â”‚   â”œâ”€â”€ topology.go         # kubectl grove topology
â”‚   â”‚   â”œâ”€â”€ health.go           # kubectl grove health
â”‚   â”‚   â”œâ”€â”€ generate.go         # kubectl grove generate (AIC)
â”‚   â”‚   â”œâ”€â”€ plan.go             # kubectl grove plan show/diff
â”‚   â”‚   â”œâ”€â”€ compare.go          # kubectl grove compare
â”‚   â”‚   â”œâ”€â”€ metrics.go          # kubectl grove metrics
â”‚   â”‚   â””â”€â”€ diag.go             # kubectl grove diag (existing)
â”‚   â”œâ”€â”€ tui/                    # Terminal UI (Bubble Tea)
â”‚   â”‚   â”œâ”€â”€ app.go              # Main TUI application
â”‚   â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â”‚   â”œâ”€â”€ hierarchy.go    # PCS â†’ PCLQ â†’ Pod tree
â”‚   â”‚   â”‚   â”œâ”€â”€ topology.go     # Rack/node heatmap
â”‚   â”‚   â”‚   â”œâ”€â”€ health.go       # Gang health dashboard
â”‚   â”‚   â”‚   â””â”€â”€ updates.go      # Rolling update progress
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ progress.go     # Progress bars
â”‚   â”‚       â”œâ”€â”€ table.go        # Tables
â”‚   â”‚       â””â”€â”€ tree.go         # Tree rendering
â”‚   â”œâ”€â”€ watch/                  # Kubernetes resource watchers
â”‚   â”‚   â”œâ”€â”€ watcher.go          # Generic watch infrastructure
â”‚   â”‚   â”œâ”€â”€ podcliqueset.go     # PCS watcher
â”‚   â”‚   â”œâ”€â”€ podgang.go          # PodGang watcher
â”‚   â”‚   â””â”€â”€ pod.go              # Pod watcher
â”‚   â”œâ”€â”€ aic/                    # AIConfigurator integration
â”‚   â”‚   â”œâ”€â”€ executor.go         # Run AIConfigurator CLI
â”‚   â”‚   â”œâ”€â”€ parser.go           # Parse AIConfigurator output
â”‚   â”‚   â”œâ”€â”€ renderer.go         # Generate Grove manifests
â”‚   â”‚   â””â”€â”€ plan.go             # Plan storage/retrieval
â”‚   â”œâ”€â”€ metrics/                # Metrics integration
â”‚   â”‚   â”œâ”€â”€ scraper.go          # Direct pod metrics scraping
â”‚   â”‚   â”œâ”€â”€ sglang.go           # SGLang metrics parser
â”‚   â”‚   â”œâ”€â”€ vllm.go             # vLLM metrics parser
â”‚   â”‚   â””â”€â”€ sla.go              # SLA comparison
â”‚   â””â”€â”€ diagnostics/            # Existing diagnostics
â”‚       â”œâ”€â”€ collector.go
â”‚       â”œâ”€â”€ resources.go
â”‚       â””â”€â”€ pods.go
â””â”€â”€ pkg/
    â””â”€â”€ types/                  # Shared types
```

---

## Feature Specifications

### P0: Foundation + Differentiation (Parallel)

#### P0.1: `kubectl grove status`

**Goal:** Match RBG's `kubectl rbg status` command + show PlacementScore.

**Usage:**
```bash
kubectl grove status <podcliqueset-name> [-n namespace]
kubectl grove status --all  # All PCS in namespace
```

**Output:**
```
ğŸ“Š Resource Overview
  Namespace: vllm-disagg
  Name:      my-inference
  Age:       2h15m

ğŸ“¦ Clique Statuses
prefill      3/3     (min: 2)    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%
decode       5/5     (min: 3)    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%
router       1/1     (min: 1)    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%

ğŸ¯ PodGang Status
my-inference-0    Running    PlacementScore: 0.95 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–“â–‘

âˆ‘ Summary: 3 cliques | 9/9 Ready | 1/1 Gangs Running
```

**Data Sources:**
- `PodCliqueSet.Status.AvailableReplicas`
- `PodClique.Status.ReadyReplicas`, `ScheduledReplicas`
- `PodGang.Status.Phase`, `PlacementScore`
- `PodClique.Spec.MinAvailable`

---

#### P0.2: `kubectl grove topology`

**Goal:** Visualize pod placement across cluster topology (RBG doesn't have this).

**Usage:**
```bash
kubectl grove topology <podcliqueset-name> [-n namespace]
kubectl grove topology <podcliqueset-name> --watch
```

**Output:**
```
â”Œâ”€ ClusterTopology: grove-topology â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hierarchy: region â†’ zone â†’ rack â†’ host â†’ numa                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PodCliqueSet: my-inference    PlacementScore: 0.92 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–“â–‘

TopologyConstraint: packDomain=rack

rack-1 [optimal]  12 GPUs allocated
â”œâ”€ node-1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (8/8 GPUs)
â”‚  â”œâ”€ prefill-0  Running  gpu:0-3
â”‚  â””â”€ prefill-1  Running  gpu:4-7
â”œâ”€ node-2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (8/8 GPUs)
â”‚  â”œâ”€ prefill-2  Running  gpu:0-3
â”‚  â””â”€ decode-0   Running  gpu:4-7
â””â”€ node-3: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ (4/8 GPUs)
   â”œâ”€ decode-1   Running  gpu:0-1
   â””â”€ decode-2   Running  gpu:2-3

rack-2 [fragmented] âš   2 GPUs allocated
â””â”€ node-5: â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ (2/8 GPUs)
   â””â”€ router-0   Running  gpu:0-1

âš  Warning: Pods split across 2 racks. PlacementScore: 0.72
  Recommendation: Consolidate to rack-1 for optimal NVLink connectivity
```

**Data Sources:**
- `ClusterTopology` CRD - topology hierarchy
- `PodGang.Status.PlacementScore`
- `PodGang.Spec.TopologyConstraint`
- `Pod.Spec.NodeName` + node labels
- Node GPU allocations from `nvidia.com/gpu`

---

### P1: AIConfigurator Integration

#### P1.1: `kubectl grove generate`

**Goal:** Match RBG's `kubectl rbg llm generate` command.

**Usage:**
```bash
kubectl grove generate \
  --model QWEN3_32B \
  --system h200_sxm \
  --total-gpus 32 \
  --backend sglang \
  --isl 4000 --osl 1000 \
  --ttft 300 --tpot 10 \
  --save-dir /tmp/output
```

**Workflow:**
1. Check if `aiconfigurator` CLI is installed
2. Run AIConfigurator with provided parameters
3. Parse output (prefill workers, decode workers, TP/PP/DP configs)
4. Generate Grove `PodCliqueSet` YAML for both disagg and agg modes
5. Optionally store plan as ConfigMap for later comparison

**Output:**
```
âœ“ AIConfigurator completed successfully

Plan 1: Prefill-Decode Disaggregated Mode
  File: /tmp/output/qwen3-32b-sglang-disagg.yaml
  Configuration:
    - Prefill Workers: 4 (tp1, 1 GPU each)
    - Decode Workers: 1 (tp4, 4 GPUs)
    - Total GPU Usage: 8
  Expected Performance:
    - Throughput: 804 tok/s/gpu
    - TTFT: 486ms
    - TPOT: 9.16ms

Plan 2: Aggregated Mode
  File: /tmp/output/qwen3-32b-sglang-agg.yaml
  ...

To deploy:
  kubectl apply -f /tmp/output/qwen3-32b-sglang-disagg.yaml

To store plan for later comparison:
  kubectl grove plan store my-inference -f /tmp/output/qwen3-32b-sglang-disagg.yaml
```

---

#### P1.2: `kubectl grove plan`

**Goal:** Store and display AIConfigurator plans for later comparison.

**Usage:**
```bash
# Store a plan
kubectl grove plan store <name> -f <yaml-or-json>

# Show stored plan
kubectl grove plan show <podcliqueset-name>

# Compare plan to deployed config
kubectl grove plan diff <podcliqueset-name>
```

**Storage:** ConfigMap with label `grove.io/aic-plan: <podcliqueset-name>`

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-inference-aic-plan
  labels:
    grove.io/aic-plan: my-inference
data:
  plan.json: |
    {
      "model": "QWEN3_32B",
      "system": "h200_sxm",
      "serving_mode": "disagg",
      "config": {
        "prefill_workers": 4,
        "decode_workers": 1,
        "prefill_tp": 1,
        "decode_tp": 4
      },
      "expected": {
        "throughput_tokens_per_sec_per_gpu": 804.83,
        "ttft_ms": 486.53,
        "tpot_ms": 9.16
      },
      "sla": {
        "ttft_ms": 300,
        "tpot_ms": 10
      }
    }
```

---

#### P1.3: `kubectl grove health`

**Goal:** Monitor gang health with termination countdown.

**Usage:**
```bash
kubectl grove health <podcliqueset-name> [-n namespace]
kubectl grove health --all
kubectl grove health <name> --watch
```

**Output:**
```
ğŸ¥ Gang Health Dashboard

PodCliqueSet: my-inference

â”Œâ”€ PodGang: my-inference-0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase: Running    PlacementScore: 0.95                            â”‚
â”‚ Status: âœ“ Healthy                                                 â”‚
â”‚                                                                   â”‚
â”‚ Clique Health:                                                    â”‚
â”‚   prefill   3/3 ready  (min: 2)  âœ“ Above threshold                â”‚
â”‚   decode    5/5 ready  (min: 3)  âœ“ Above threshold                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ PodGang: my-inference-1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase: Running    PlacementScore: 0.72                            â”‚
â”‚ Status: âš  UNHEALTHY (Termination in 3h 42m)                       â”‚
â”‚                                                                   â”‚
â”‚ Issues:                                                           â”‚
â”‚   - prefill-2: Pending (Unschedulable: insufficient GPU)          â”‚
â”‚                                                                   â”‚
â”‚ TerminationDelay: 4h (configured)                                 â”‚
â”‚ Time Remaining: 3h 42m â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 78%                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Summary: 1/2 gangs healthy | 1 gang at risk of termination
```

---

### P2: TUI Mode

#### P2.1: `kubectl grove tui`

**Goal:** Interactive terminal UI for real-time monitoring.

**Usage:**
```bash
kubectl grove tui [-n namespace]
```

**Interface:**
```
â”Œâ”€ kubectl grove â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Namespace: vllm-disagg    Cluster: prod-us-west-2                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [1] Hierarchy  [2] Topology  [3] Health  [4] Metrics  [q]uit               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  PodCliqueSet: my-inference (2/2 available)                                â”‚
â”‚  â”œâ”€â”€ PodGang: my-inference-0 [Running, Score: 0.95]                        â”‚
â”‚  â”‚   â”œâ”€â”€ prefill [3/3] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%                               â”‚
â”‚  â”‚   â”‚   â”œâ”€â”€ pod-abc  Running  node-1  gpu:0-3                             â”‚
â”‚  â”‚   â”‚   â”œâ”€â”€ pod-def  Running  node-1  gpu:4-7                             â”‚
â”‚  â”‚   â”‚   â””â”€â”€ pod-ghi  Running  node-2  gpu:0-3                             â”‚
â”‚  â”‚   â””â”€â”€ decode [5/5] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%                                â”‚
â”‚  â”‚       â””â”€â”€ (5 pods)                                                      â”‚
â”‚  â””â”€â”€ PodGang: my-inference-1 [Running, Score: 0.72] âš                       â”‚
â”‚      â””â”€â”€ ...                                                               â”‚
â”‚                                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â†‘/â†“: Navigate  Enter: Expand  r: Refresh  ?: Help                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Views:**
1. **Hierarchy** - PCS â†’ PodGang â†’ PodClique â†’ Pod tree
2. **Topology** - Visual rack/node layout with PlacementScore
3. **Health** - Gang health with termination countdown
4. **Metrics** - Live throughput/latency (when P3 is complete)

**Implementation:**
- Framework: [Bubble Tea](https://github.com/charmbracelet/bubbletea)
- Styling: [Lip Gloss](https://github.com/charmbracelet/lipgloss)
- Real-time: K8s watch API

---

### P3: Metrics Integration

#### P3.1: `kubectl grove metrics`

**Goal:** Scrape inference engine metrics directly from pods.

**Usage:**
```bash
kubectl grove metrics <podcliqueset-name> [-n namespace]
kubectl grove metrics <name> --watch
kubectl grove metrics <name> --json
```

**Output:**
```
Live Metrics: my-inference (last 5m)

Throughput:
  Input:  12,450 tok/s
  Output: 8,230 tok/s
  Per-GPU: 756 tok/s/gpu (plan: 804, -6%)

Latency:
  TTFT p50:  125ms    TTFT p99:  342ms (SLA: 300ms) âŒ
  TPOT p50:  6.1ms    TPOT p99:  8.2ms (SLA: 10ms) âœ“

Queue:
  Queue Depth: 12 requests
  Active Requests: 48

Per-Role:
  prefill: Token Usage 78%
  decode:  Token Usage 45% âš  Underutilized
```

**Implementation:**
- Direct HTTP scrape from pod IPs (no Prometheus dependency)
- Auto-detect engine: SGLang (`/metrics`), vLLM (`/metrics`), TRT-LLM
- Compare against SLA from stored plan

---

#### P3.2: `kubectl grove compare`

**Goal:** Compare AIConfigurator predictions to actual performance.

**Usage:**
```bash
kubectl grove compare <podcliqueset-name> [-n namespace]
```

**Output:**
```
Plan vs Actual Comparison: my-inference

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric              â”‚ Planned      â”‚ Actual       â”‚ Status     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Throughput          â”‚ 804 tok/s/gpuâ”‚ 756 tok/s/gpuâ”‚ âš  -6%      â”‚
â”‚ TTFT (p99)          â”‚ â‰¤300ms       â”‚ 342ms        â”‚ âŒ EXCEED  â”‚
â”‚ TPOT (p99)          â”‚ â‰¤10ms        â”‚ 8.2ms        â”‚ âœ“ OK       â”‚
â”‚ PlacementScore      â”‚ 1.0          â”‚ 0.72         â”‚ âš  -28%     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Diagnosis:
  PlacementScore 0.72 â†’ prefill pods split across 2 racks

Recommendations:
  1. [HIGH] Reschedule prefill-2, prefill-3 to consolidate on rack-1
     Expected: PlacementScore â†’ 0.95, TTFT â†’ 280ms
```

---

### P4: Future Features

- `kubectl grove recommend` - AI-powered recommendations
- `kubectl grove dashboard` - Web-based dashboard (Streamlit)
- k9s plugin integration

---

## Technical Specifications

### Dependencies

```go
require (
    github.com/alecthomas/kong v1.x          // CLI framework
    github.com/charmbracelet/bubbletea v1.x  // TUI
    github.com/charmbracelet/lipgloss v1.x   // TUI styling
    github.com/charmbracelet/bubbles v0.x    // TUI components
    k8s.io/client-go v0.34.x                 // K8s client
)
```

### Configuration

```yaml
# ~/.config/kubectl-grove/config.yaml
defaults:
  namespace: default
  operator_namespace: grove-system

metrics:
  scrape_timeout: 5s
  port: 8000

tui:
  refresh_interval: 2s
  color_scheme: auto

aiconfigurator:
  path: aiconfigurator
  default_backend: sglang
```

### kubectl Plugin Installation

```bash
# Build
cd operator/cmd/kubectl-grove
go build -o kubectl-grove .

# Install (move to PATH)
sudo mv kubectl-grove /usr/local/bin/

# Verify
kubectl grove --help
```

Future: Distribute via krew.

---

## Implementation Roadmap

### Phase 0: Foundation (Week 1-2)
- [ ] Rename arborist â†’ kubectl-grove
- [ ] Restructure CLI with subcommands
- [ ] Implement `kubectl grove status`
- [ ] Implement `kubectl grove topology`
- [ ] Set up test infrastructure

### Phase 1: AIConfigurator Integration (Week 3-4)
- [ ] Implement `kubectl grove generate`
- [ ] Implement AIConfigurator executor/parser
- [ ] Implement Grove manifest renderer
- [ ] Implement `kubectl grove plan store/show/diff`
- [ ] Implement `kubectl grove health`

### Phase 2: TUI Mode (Week 5-8)
- [ ] Set up Bubble Tea framework
- [ ] Implement hierarchy view
- [ ] Implement topology view
- [ ] Implement health view
- [ ] Add K8s watch for real-time updates

### Phase 3: Metrics Integration (Week 9-12)
- [ ] Implement direct pod metrics scraping
- [ ] Implement `kubectl grove metrics`
- [ ] Implement `kubectl grove compare`
- [ ] Add SLA comparison

---

## GitHub Issues

Create the following issues for tracking:

1. **[P0] kubectl grove status command** - Match RBG status + PlacementScore
2. **[P0] kubectl grove topology command** - Topology visualization (differentiator)
3. **[P1] kubectl grove generate command** - AIConfigurator integration
4. **[P1] kubectl grove plan commands** - Plan storage and diff
5. **[P1] kubectl grove health command** - Gang health monitoring
6. **[P2] kubectl grove tui** - Interactive terminal UI
7. **[P3] kubectl grove metrics command** - Direct pod metrics scraping
8. **[P3] kubectl grove compare command** - Plan vs actual comparison

---

## Success Metrics

1. **Adoption:** 50% of Grove users using kubectl grove within 3 months
2. **Issue Resolution:** 40% reduction in time-to-diagnosis
3. **Competitive:** Feature parity with RBG + 3 differentiating features
4. **Satisfaction:** Positive feedback on topology visualization

---

## References

- [RBG CLI Implementation](https://github.com/kubernetes-sigs/rbgs/tree/main/cmd/cli)
- [AIConfigurator](https://github.com/ai-dynamo/aiconfigurator)
- [srtctl Dashboard](https://github.com/ishandhanani/srt-slurm) - Visualization inspiration
- [Bubble Tea](https://github.com/charmbracelet/bubbletea) - TUI framework
- [Grove Competitive Analysis](https://gist.github.com/athreesh/3f3c868f2e5f8b02c1f632159788af98)

---

## Changelog

- **2026-01-16:** Renamed to kubectl-grove, updated priorities per PM decisions
- **2026-01-15:** Initial draft (as arborist)
